{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction to Cross-Validation - Lab\n","\n","## Introduction\n","\n","In this lab, you'll be able to practice your cross-validation skills!\n","\n","\n","## Objectives\n","\n","You will be able to:\n","\n","- Perform cross validation on a model\n","- Compare and contrast model validation strategies"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started\n","\n","We included the code to pre-process the Ames Housing dataset below. This is done for the sake of expediency, although it may result in data leakage and therefore overly optimistic model metrics."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","ames = pd.read_csv('ames.csv')\n","\n","continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n","categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n","\n","ames_cont = ames[continuous]\n","\n","# log features\n","log_names = [f'{column}_log' for column in ames_cont.columns]\n","\n","ames_log = np.log(ames_cont)\n","ames_log.columns = log_names\n","\n","# normalize (subract mean and divide by std)\n","\n","def normalize(feature):\n","    return (feature - feature.mean()) / feature.std()\n","\n","ames_log_norm = ames_log.apply(normalize)\n","\n","# one hot encode categoricals\n","ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n","\n","preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n","\n","X = preprocessed.drop('SalePrice_log', axis=1)\n","y = preprocessed['SalePrice_log']"]},{"cell_type":"markdown","metadata":{},"source":["## Train-Test Split\n","\n","Perform a train-test split with a test set of 20% and a random state of 4."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Import train_test_split from sklearn.model_selection\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (1168, 47)\n","X_test shape: (292, 47)\n","y_train shape: (1168,)\n","y_test shape: (292,)\n"]}],"source":["# Split the data into training and test sets (assign 20% to test set)\n","#20% is the same as 0.2\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state =4)\n","#display the shape of the resulting datasets\n","print(\"X_train shape:\",X_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Fit a Model\n","\n","Fit a linear regression model on the training set"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Import LinearRegression from sklearn.linear_model\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Instantiate and fit a linear regression model\n","#initialize the linear regression model\n","model = LinearRegression()\n","#fit the model on the training data\n","model.fit(X_train,y_train)\n","#make predictions on the test set\n","y_pred = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate MSE\n","\n","Calculate the mean squared error on the test set"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Import mean_squared_error from sklearn.metrics\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["0.1523399721070817"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Calculate MSE on test set\n","mse = mean_squared_error(y_test,y_pred)\n","mse\n"]},{"cell_type":"markdown","metadata":{},"source":["## Cross-Validation using Scikit-Learn\n","\n","Now let's compare that single test MSE to a cross-validated test MSE."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Import cross_val_score from sklearn.model_selection\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE scores for each fold: [0.12431546 0.19350065 0.1891053  0.17079325 0.20742705]\n"]}],"source":["# Find MSE scores for a 5-fold cross-validation\n","score = cross_val_score(model,X,y, cv=5,scoring = 'neg_mean_squared_error')\n","#convert negative MSE score to positive\n","mse_scores = -score\n","print('MSE scores for each fold:', mse_scores)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["0.1770283421000112"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Get the average MSE score\n","average_mse = mse_scores.mean()\n","average_mse"]},{"cell_type":"markdown","metadata":{},"source":["Compare and contrast the results. What is the difference between the train-test split and cross-validation results? Do you \"trust\" one more than the other?"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["\"Recommend cross_validation because its results most likely reflects the model's true perfomance on unseen data.The slightly lower MSE from the train test split could be due to a favorable split or just variability.\\n\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Your answer here\n","\"\"\"Recommend cross_validation because its results most likely reflects the model's true perfomance on unseen data.The slightly lower MSE from the train test split could be due to a favorable split or just variability.\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up: Let's Build It from Scratch!\n","\n","### Create a Cross-Validation Function\n","\n","Write a function `kfolds(data, k)` that splits a dataset into `k` evenly sized pieces. If the full dataset is not divisible by `k`, make the first few folds one larger then later ones.\n","\n","For example, if you had this dataset:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>color</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>orange</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yellow</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>green</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>blue</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>indigo</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>violet</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    color\n","0     red\n","1  orange\n","2  yellow\n","3   green\n","4    blue\n","5  indigo\n","6  violet"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["example_data = pd.DataFrame({\n","    \"color\": [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\n","})\n","example_data"]},{"cell_type":"markdown","metadata":{},"source":["`kfolds(example_data, 3)` should return:\n","\n","* a dataframe with `red`, `orange`, `yellow`\n","* a dataframe with `green`, `blue`\n","* a dataframe with `indigo`, `violet`\n","\n","Because the example dataframe has 7 records, which is not evenly divisible by 3, so the \"leftover\" 1 record extends the length of the first dataframe."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def kfolds(data, k):\n","    folds = []\n","    \n","    #determine the size of each fold\n","    n = len(data)# n = total number of items and k = number of folds\n","    base_size = n // k #this tells how many full items each fold will contain\n","    larger_folds = n % k #this calculates how many folds need to have one extra item to account for any reminder\n","\n","    start_index = 0\n","    for i in range (k):\n","        #calculate the end index for this fold\n","        fold_size = base_size + 1 if i < larger_folds else base_size\n","        end_index = start_index + fold_size\n","\n","    #slice the data to create fold\n","    fold = data.iloc[start_index:end_index]\n","    folds.append(fold)\n","\n","    #update the start index for the next fold\n","    start_index = end_index\n","    \n","    return folds"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    color\n","0     red\n","1  orange \n","\n"]}],"source":["results = kfolds(example_data, 3)\n","for result in results:\n","    print(result, \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### Apply Your Function to the Ames Housing Data\n","\n","Get folds for both `X` and `y`."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of X_folds: 1\n","Number of y_folds: 1\n","Sample X_folds: [     LotArea_log  1stFlrSF_log  GrLivArea_log  BldgType_2fmCon  \\\n","0      -0.133185     -0.803295       0.529078                0   \n","1       0.113403      0.418442      -0.381715                0   \n","2       0.419917     -0.576363       0.659449                0   \n","3       0.103311     -0.439137       0.541326                0   \n","4       0.878108      0.112229       1.281751                0   \n","..           ...           ...            ...              ...   \n","287    -0.208982     -0.795950      -1.538509                0   \n","288     0.156994     -0.645537      -1.395230                0   \n","289    -0.070186     -1.445511      -0.079173                0   \n","290     1.053039     -0.074628       0.874786                0   \n","291    -0.898448     -0.522097       0.539579                1   \n","\n","     BldgType_Duplex  BldgType_Twnhs  BldgType_TwnhsE  KitchenQual_Fa  \\\n","0                  0               0                0               0   \n","1                  0               0                0               0   \n","2                  0               0                0               0   \n","3                  0               0                0               0   \n","4                  0               0                0               0   \n","..               ...             ...              ...             ...   \n","287                0               0                0               0   \n","288                0               0                0               0   \n","289                0               0                0               0   \n","290                0               0                0               0   \n","291                0               0                0               1   \n","\n","     KitchenQual_Gd  KitchenQual_TA  ...  Neighborhood_NoRidge  \\\n","0                 1               0  ...                     0   \n","1                 0               1  ...                     0   \n","2                 1               0  ...                     0   \n","3                 1               0  ...                     0   \n","4                 1               0  ...                     1   \n","..              ...             ...  ...                   ...   \n","287               0               1  ...                     0   \n","288               0               1  ...                     0   \n","289               0               1  ...                     0   \n","290               1               0  ...                     0   \n","291               0               0  ...                     0   \n","\n","     Neighborhood_NridgHt  Neighborhood_OldTown  Neighborhood_SWISU  \\\n","0                       0                     0                   0   \n","1                       0                     0                   0   \n","2                       0                     0                   0   \n","3                       0                     0                   0   \n","4                       0                     0                   0   \n","..                    ...                   ...                 ...   \n","287                     0                     0                   0   \n","288                     0                     0                   0   \n","289                     0                     0                   0   \n","290                     0                     0                   0   \n","291                     0                     0                   1   \n","\n","     Neighborhood_Sawyer  Neighborhood_SawyerW  Neighborhood_Somerst  \\\n","0                      0                     0                     0   \n","1                      0                     0                     0   \n","2                      0                     0                     0   \n","3                      0                     0                     0   \n","4                      0                     0                     0   \n","..                   ...                   ...                   ...   \n","287                    0                     0                     0   \n","288                    1                     0                     0   \n","289                    0                     0                     0   \n","290                    0                     0                     0   \n","291                    0                     0                     0   \n","\n","     Neighborhood_StoneBr  Neighborhood_Timber  Neighborhood_Veenker  \n","0                       0                    0                     0  \n","1                       0                    0                     1  \n","2                       0                    0                     0  \n","3                       0                    0                     0  \n","4                       0                    0                     0  \n","..                    ...                  ...                   ...  \n","287                     0                    0                     0  \n","288                     0                    0                     0  \n","289                     0                    0                     0  \n","290                     0                    0                     0  \n","291                     0                    0                     0  \n","\n","[292 rows x 47 columns]]\n","Sample y_folds: [0      0.559876\n","1      0.212692\n","2      0.733795\n","3     -0.437232\n","4      1.014303\n","         ...   \n","287   -1.599589\n","288   -0.781758\n","289   -0.205548\n","290    0.840475\n","291   -0.511642\n","Name: SalePrice_log, Length: 292, dtype: float64]\n"]}],"source":["# Apply kfolds() to ames_data with 5 folds\n","k = 5 #number of folds\n","X_folds = kfolds(X ,k)\n","y_folds = kfolds(y ,k)\n","# Check lengths and samples of folds\n","print(\"Number of X_folds:\", len(X_folds))\n","print(\"Number of y_folds:\", len(y_folds))\n","print(\"Sample X_folds:\", X_folds[:2])  # Print first two folds for X\n","print(\"Sample y_folds:\", y_folds[:2])  # Print first two folds for y\n"]},{"cell_type":"markdown","metadata":{},"source":["### Perform a Linear Regression for Each Fold and Calculate the Test Error\n","\n","Remember that for each fold you will need to concatenate all but one of the folds to represent the training data, while the one remaining fold represents the test data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Replace None with appropriate code\n","test_errs = []\n","k = 5\n","\n","for n in range(k):\n","    # Split into train and test for the fold\n","    X_train = pd.concat([X_folds[i] for i in range (k) if i != n],ignore_index = True)\n","    X_test = X_folds[n]\n","    y_train = pd.concat([y_folds[i] for i in range (k) if i != n],ignore_index = True)\n","    y_test = y_folds[n]\n","    \n","    # Fit a linear regression model\n","    model = LinearRegression()\n","    model.fit(X_train,y_train)\n","    \n","    # Evaluate test errors\n","    y_pred = model.predict(X_test)\n","\n","    #calculate and store the MSE for the current fold\n","    mse = mean_squared_error(y_test,y_pred)\n","    test_errs.append(mse)\n","\n","print(test_errs)"]},{"cell_type":"markdown","metadata":{},"source":["If your code was written correctly, these should be the same errors as scikit-learn produced with `cross_val_score` (within rounding error). Test this out below:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare your results with sklearn results\n"]},{"cell_type":"markdown","metadata":{},"source":["This was a bit of work! Hopefully you have a clearer understanding of the underlying logic for cross-validation if you attempted this exercise."]},{"cell_type":"markdown","metadata":{},"source":["##  Summary "]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are more robust than train-test split."]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":2}
